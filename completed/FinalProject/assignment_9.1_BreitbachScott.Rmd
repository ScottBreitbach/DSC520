---
title: "Assignment 9.1"
author: "Scott Breitbach"
date: "7/27/2020"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)
knitr::opts_knit$set(root.dir = "C:/Users/micha/OneDrive/Documents/GitHub/DSC520/")
# Read data files
library(readr)
# Plot data
library(ggplot2)
# Work with dates-times
library(lubridate)
# used for padding strings
library(stringr)
```

## Assignment 9.1: Final Project Step 2: Cleaning Your Data and Exploratory Data Analysis

```{r load husker data, message = FALSE}
# Load game data
Huskers_2019 <- read_csv("completed/FinalProject/data/Huskers_2019.csv")
Huskers_2018 <- read_csv("completed/FinalProject/data/Huskers_2018.csv")
Huskers_2017 <- read_csv("completed/FinalProject/data/Huskers_2017.csv")
Huskers_2016 <- read_csv("completed/FinalProject/data/Huskers_2016.csv")
Huskers_2015 <- read_csv("completed/FinalProject/data/Huskers_2015.csv")
Huskers_2014 <- read_csv("completed/FinalProject/data/Huskers_2014.csv")
Huskers_2013 <- read_csv("completed/FinalProject/data/Huskers_2013.csv")
```

```{r clean husker data}
# Combine data
Husker_games <- rbind(Huskers_2013, Huskers_2014, Huskers_2015, Huskers_2016, Huskers_2017, Huskers_2018, Huskers_2019)

# Remove ranking from school names
Husker_games$School <- gsub("[[:digit:]]", "", Husker_games$School)
Husker_games$School <- gsub("[[:punct:]]+[[:punct:]] ", "", Husker_games$School)
Husker_games$Opponent <- gsub("[[:digit:]]", "", Husker_games$Opponent)
Husker_games$Opponent <- gsub("[[:punct:]]+[[:punct:]] ", "", Husker_games$Opponent)

# Rename unnamed columns
names(Husker_games)[6] <- "Home"
names(Husker_games)[9] <- "Win"

# Convert W/L and NA/@ to 1/0
Husker_games$Win <- as.numeric(as.factor(Husker_games$Win))-1
Husker_games$Home <- as.numeric(as.factor(Husker_games$Home))-1
Husker_games$Home[is.na(Husker_games$Home)] <- 1

# Remove extra columns
Husker_games <- Husker_games[c("Date", "Time", "Day", "School", "Home", "Opponent", "Win")]

# Convert dates
Husker_games$Date <- mdy(Husker_games$Date)
Husker_games$Day <- wday(Husker_games$Date, label = TRUE)

# Keep only months: Sept, Oct, Nov
Husker_games <- Husker_games[month(Husker_games$Date) >= 9 & month(Husker_games$Date) <= 11, ]

# Cleanup
rm(Huskers_2013, Huskers_2014, Huskers_2015, Huskers_2016, Huskers_2017, Huskers_2018, Huskers_2019)
```

```{r load police data}
## Arrests and Citations
arrests_citations <- read_csv("completed/FinalProject/data/LPD_2013_2020_Arrests_and_Citations_De_Coded.csv")

## Incident Reports
incidents_2017_2020 <- read_csv("completed/FinalProject/data/LPD_2017_2020_Incident_Reports.csv")
incidents_2016 <- read_csv("completed/FinalProject/data/LPD_Incident_Reports_2016.csv")
incidents_2015 <- read_csv("completed/FinalProject/data/LPD_Incident_Reports_2015.csv")
incidents_2014 <- read_csv("completed/FinalProject/data/LPD_Incident_Reports_2014.csv")
incidents_2013 <- read_csv("completed/FinalProject/data/LPD_Incident_Reports_2013.csv")

## Traffic Crashes
Trf_Crash_13 <- read_csv("completed/FinalProject/data/Traffic_Crashes_2013.csv")
Trf_Crash_14 <- read_csv("completed/FinalProject/data/Traffic_Crashes_2014.csv")
Trf_Crash_15 <- read_csv("completed/FinalProject/data/Traffic_Crashes_2015.csv")
Trf_Crash_16 <- read_csv("completed/FinalProject/data/Traffic_Crashes_2016.csv")
Trf_Crash_17 <- read_csv("completed/FinalProject/data/Traffic_Crashes_2017.csv")
Trf_Crash_18 <- read_csv("completed/FinalProject/data/Traffic_Crashes_2018.csv")
Trf_Crash_19 <- read_csv("completed/FinalProject/data/Traffic_Crashes_2019.csv")

## Traffic Stops
Trf_Stop_13 <- read_csv("completed/FinalProject/data/LPD_traffic_stops_2013.csv")
Trf_Stop_14 <- read_csv("completed/FinalProject/data/LPD_traffic_stops_2014.csv")
Trf_Stop_15 <- read_csv("completed/FinalProject/data/LPD_traffic_stops_2015.csv")
Trf_Stop_16 <- read_csv("completed/FinalProject/data/LPD_traffic_stops_2016.csv")
Trf_Stop_17 <- read_csv("completed/FinalProject/data/LPD_traffic_stops_2017.csv")
Trf_Stop_18 <- read_csv("completed/FinalProject/data/LPD_traffic_stops_2018.csv")
Trf_Stop_19 <- read_csv("completed/FinalProject/data/LPD_traffic_stops_2019.csv")
```

```{r clean police datA}
## ARRESTS AND CITATIONS
a_c.13_20 <- arrests_citations[c("CHARGED", "VDATE", "VTIM")]
names(a_c.13_20)[1:3] <- c("Charge","Date", "Time")
# Parse dates & times
a_c.13_20$Date <- parse_date(a_c.13_20$Date, "%Y/%m/%d %H:%M:%S+00")
a_c.13_20$Time <- str_pad(a_c.13_20$Time, 4, pad = "0")
a_c.13_20$Time <- parse_time(a_c.13_20$Time, "%H%M")
# Remove all but Sep, Oct, Nov
a_c.13_20 <- a_c.13_20[month(a_c.13_20$Date) >= 9 & month(a_c.13_20$Date) <= 11, ]
# Remove dates before 2013 or after 2019
a_c.13_19 <- a_c.13_20[year(a_c.13_20$Date) >= 2013 & year(a_c.13_20$Date) <= 2019, ]
# Remove NAs
a_c.13_19 <- na.omit(a_c.13_19)
# Day of week column
a_c.13_19$Day <- wday(a_c.13_19$Date, label = TRUE)

## INCIDENT REPORTS
# 2017-2020 data set:
#  Remove / Rename columns
inc.17_20 <- incidents_2017_2020[c("CALL_TYPE", "From_Date", "From_Time")]
names(inc.17_20)[1:3] <- c("Type", "Date", "Time")
#  Parse dates
inc.17_20$Date <- ymd(inc.17_20$Date)
# 2015 & 2016 data sets:
inc.15_16 <- rbind(incidents_2015, incidents_2016)
#  Remove / Rename columns
inc.15_16 <- inc.15_16[c("CALL_TYPE", "DATE_FROM", "TIME_FROM")]
names(inc.15_16)[1:3] <- c("Type", "Date", "Time")
#  Parse dates
inc.15_16$Date <- parse_date(inc.15_16$Date, "%Y/%m/%d %H:%M:%S+00")
# 2013 & 2014 data sets:
inc.13_14 <- rbind(incidents_2013, incidents_2014)
#  Remove / Rename columns
inc.13_14 <- inc.13_14[c("CALL_TYPE", "DATE_FROM", "TIME_FROM")]
names(inc.13_14)[1:3] <- c("Type", "Date", "Time")
#  Parse dates
inc.13_14$Date <- mdy(inc.13_14$Date)
# Combine data sets (2013-2020):
inc.13_20 <- rbind(inc.13_14, inc.15_16, inc.17_20)
#  Parse times
inc.13_20$Time <- str_pad(inc.13_20$Time, 4, pad = "0")
inc.13_20$Time <- parse_time(inc.13_20$Time, "%H%M")
#  Remove all but Sep, Oct, Nov
inc.13_20 <- inc.13_20[month(inc.13_20$Date) >= 9 & month(inc.13_20$Date) <= 11, ]
#  Remove dates before 2013 or after 2019
inc.13_19 <- inc.13_20[year(inc.13_20$Date) >= 2013 & year(inc.13_20$Date) <= 2019, ]
#  Remove NAs
inc.13_19 <- na.omit(inc.13_19)
#  Add Day of week column
inc.13_19$Day <- wday(inc.13_19$Date, label = TRUE)

## TRAFFIC CRASHES
#  Rename columns and merge
names(Trf_Crash_18)[16] <- "FID"
names(Trf_Crash_19)[16] <- "FID"
t_c.13_18 <- rbind(Trf_Crash_13, Trf_Crash_14, Trf_Crash_15, Trf_Crash_16, Trf_Crash_17, Trf_Crash_18)
#  Format dates and merge
t_c.13_18$DOA <- parse_date(t_c.13_18$DOA, "%Y/%m/%d %H:%M:%S+00")
Trf_Crash_19$DOA <- as.POSIXct(Trf_Crash_19$DOA/1000, origin = "1970-01-01")
Trf_Crash_19$DOA <- as.character(Trf_Crash_19$DOA)
Trf_Crash_19$DOA <- parse_date(Trf_Crash_19$DOA, "%Y-%m-%d %H:%M:%S")
t_c.13_19 <- rbind(t_c.13_18, Trf_Crash_19)
#  Remove / Rename columns
t_c.13_19 <- t_c.13_19[c("TYPE", "ACTION", "PED", "BIKE", "MC", "MOPED", "TRAIN", "TRUCK", "BUS", "DOA", "TOA")]
names(t_c.13_19)[1:11] <- c("Type", "Action", "Pedestrian", "Bike", "Motorcycle", "Moped", "Train", "Truck", "Bus", "Date", "Time")
#  Remove all but Sep, Oct, Nov
t_c.13_19 <- t_c.13_19[month(t_c.13_19$Date) >= 9 & month(t_c.13_19$Date) <= 11, ]
#  Remove dates before 2013 or after 2019
t_c.13_19 <- t_c.13_19[year(t_c.13_19$Date) >= 2013 & year(t_c.13_19$Date) <= 2019, ]
#  Parse times
t_c.13_19$Time <- str_pad(t_c.13_19$Time, 4, pad = "0")
t_c.13_19$Time <- parse_time(t_c.13_19$Time, "%H%M")
#  Remove NAs
t_c.13_19 <- na.omit(t_c.13_19)
#  Add Day of week column
t_c.13_19$Day <- wday(t_c.13_19$Date, label = TRUE)

## TRAFFIC STOPS
#  Rename columns and merge
names(Trf_Stop_14)[4] <- "SEX"
names(Trf_Stop_18)[8] <- "FID"
t_s.13.16 <- rbind(Trf_Stop_13, Trf_Stop_16)
t_s.14_15 <- rbind(Trf_Stop_14, Trf_Stop_15)
t_s.17_19 <- rbind(Trf_Stop_17, Trf_Stop_18, Trf_Stop_19)
# Parse times and merge
t_s.13.16$TIME <- parse_time(t_s.13.16$TIME)
t_s.14_15$TIME <- parse_time(t_s.14_15$TIME, "%Y/%M/%D %H:%M:%S+00")
t_s.17_19$TIME <- gsub(":XX", "", t_s.17_19$TIME)
t_s.17_19$TIME <- parse_time(t_s.17_19$TIME, "%H:%M")
t_s.13_19 <- rbind(t_s.13.16, t_s.14_15, t_s.17_19)
#  Remove / Rename columns
t_s.13_19 <- t_s.13_19[c("REASON", "DATE", "TIME")]
names(t_s.13_19)[1:3] <- c("Reason", "Date", "Time")
#  Parse dates
t_s.13_19$Date <- parse_date(t_s.13_19$Date, "%Y/%m/%d %H:%M:%S+00")
#  Remove all but Sep, Oct, Nov
t_s.13_19 <- t_s.13_19[month(t_s.13_19$Date) >= 9 & month(t_s.13_19$Date) <= 11, ]
#  Remove dates before 2013 or after 2019
t_s.13_19 <- t_s.13_19[year(t_s.13_19$Date) >= 2013 & year(t_s.13_19$Date) <= 2019, ]
#  Remove NAs
t_s.13_19 <- na.omit(t_s.13_19)
#  Add Day of week column
t_s.13_19$Day <- wday(t_s.13_19$Date, label = TRUE)

### CLEANUP
rm(arrests_citations, a_c.13_20)
rm(incidents_2017_2020, incidents_2016, incidents_2015, incidents_2014, incidents_2013)
rm(inc.17_20, inc.15_16, inc.13_14, inc.13_20)
rm(Trf_Crash_13, Trf_Crash_14, Trf_Crash_15, Trf_Crash_16, Trf_Crash_17, Trf_Crash_18, Trf_Crash_19)
rm(t_c.13_18)
rm(Trf_Stop_13, Trf_Stop_14, Trf_Stop_15, Trf_Stop_16, Trf_Stop_17, Trf_Stop_18, Trf_Stop_19)
rm(t_s.13.16, t_s.14_15, t_s.17_19)
```

### Data importing and cleaning steps are explained in the text and in the Github exercises. (Tell me why you are doing the data cleaning activities that you perform). Follow a logical process.

With the Husker game data, some of the teams had numbers in front of them, presumably indicating their ranking if they were in the top 25 going into that game. I had to remove the numbers, characters, and spaces in order to unify the team names. I also had to convert the dates and times to the appropriate formats using lubridate.

I will change some of the information into more useful formats. For example the away games have an "@" sign indicating they are at the opposing team's field. This column will be relabeled "Home"; the "@"s will be converted to 0's and the "NA"s converted to 1's. The Win/Loss column will be relabeled "Win" and the "W"s converted to 1's and "L"s to 0's. The remaining columns will be removed.

Some of the police data was already compiled from 2013 to 2020, some from 2017 to 2020, and some was just available by year so I had to merge data sets in order to make them all 2013 to 2019 (I removed 2020 data because football season has not started). While there are a few exceptions, the vast majority of the games are in September, October, and November so I will use these three months and remove all other data.

Some of the newer data sets also had more columns. Since I am really only interested in number of events, I am paring them down to the essentials: dates, times, and the overall category (I don't plan to use the categories, but I feel they may come in useful later). Some of the rows didn't parse, but there were a small number of them (for the incident reports, there were ~136 out of >250,000 rows) so I am accepting that risk as minor.

### With a clean dataset, show what the final data set looks like. However, do not print off a data frame with 200+ rows; show me the data in the most condensed form possible.

```{r data sets}
"Game Data"
head(Husker_games)
"Arrests and Citations"
head(a_c.13_19)
"Incident Reports"
head(inc.13_19)
"Traffic Crashes"
head(t_c.13_19)
"Traffic Stops"
head(t_s.13_19)
```

### What do you not know how to do right now that you need to learn to import and cleanup your dataset?

Importing csv files was pretty straightforward using the readr library and the rbind() function to combine consecutive data sets. Cleaning was a bit more challenging. Most of the functions I could not remember off of the top of my head and I had to look them up. This ranged from removing extra numbers, characters, and spaces from the "School" and "Opponent" columns, to renaming columns and formatting dates, to removing columns and converting factors to 1s and 0s (including some NAs). 

I still need to figure out how to remove rows within certain date ranges, but since I am keeping only three of the months I think I should be able to create a "Month" column and essentially filter out (or in) the appropriate months.

### Discuss how you plan to uncover new information in the data that is not self-evident.

I plan to uncover information primarily through the use of different types of charts in order to look for patterns in the data that may not be immediately obvious. 

### What are different ways you could look at this data to answer the questions you want to answer?

I plan to take advantage of the fact that all of my data contains date-time information. This should allow me to looks for patterns based on different date-time groupings, like day of the week or time of day as well as which weekends the Huskers had home or away games and who they played against.

### Do you plan to slice and dice the data in different ways, create new variables, or join separate data frames to create new summary information? Explain

Apart from merging data sets from multiple years, I think most of the slicing and dicing I'm going to encounter will revolve around working with dates and times, especially as they relate to the dates and times of the Husker games. At a minimum, I will need to create a column for day of the week. 

In addition, I kept type of incidents listed in the police reports, which may allow me to look for correlations with certain types of incidents instead of just number of incidents in general.

### How could you summarize your data to answer key questions?

I think primarily the use of charts will be the most effective way to summarize my data and show any correlations between Husker game timing and crime and traffic incidents. I may then be able to use these correlations to predict likelihood of incidences occurring around future games.

### What types of plots and tables will help you to illustrate the findings to your questions? Ensure that all graph plots have axis titles, legend if necessary, scales are appropriate, appropriate geoms used, etc.).

I think the best way to illustrate my findings will be through the use of bar charts and histograms in order to compare the variable of interest to a baseline or to other, related variables.

### What do you not know how to do right now that you need to learn to answer your questions?

I need to figure out how to categories date and time ranges into both Husker home game weekends and morning vs evening games and Friday vs Saturday games, as well as before and after Husker games. I also need to figure out how to calculate the number of incidents occurring within a given time frame.

### Do you plan on incorporating any machine learning techniques to answer your research questions? Explain.

If there is any effect, I think I should be able to use linear or multiple regression in order to predict the number of incidents based on the different criteria I'm looking at, such as day of the week, home vs away game, and opposing team.











